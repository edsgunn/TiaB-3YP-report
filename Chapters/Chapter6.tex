% Chapter Template

\chapter{Recommendation Engine}% Main chapter title
\label{Chapter6} % Change X to a consecutive number; for referencing this chapter elsewhere, use \ref{ChapterX}


The quality of recommendation system design determines the qulaity of the the posts recommended to our users.
\\ A recent study by Epsilon found that 90\% of consumers find personalisation appealing. Plus, a further 80\% claim they are more likely to do business with a company when offered personalised experiences.
The study also found that these consumers are 10x more likely to become VIP customers, who make more than 15 purchases per year.\footfullcite{epsilon} 
That means a well-designed recommendation system can benefit the monetisation of our app in the future.
\\Based on the types of recommendation, we can divide it into personalised and non-personalised, and personalised recommendation system can be further divided into content-based filtering system and collaborative filtering system. 
The overview of recommendation system can be seen figure. \autoref{overrecomm}
\begin{figure}[ht]
\centering
\includegraphics[scale = 0.2]{overview11.png}
\caption{Overview of recommendation system}
\label{overrecomm}
\end{figure}


%-----------------------------------------------------------------------------------------------------------------------------Popularity-Based Recommendation System
\section{Popularity Based Recommendation System}
It is a type of recommendation system which works on the principle of popularity and or anything which is in trend. These systems check about the product or movie which are in trend or are most popular among the users and directly recommend those. 
Instead of recommending posts only based on the number of likes that the posts received, we can give weighting to each parameter involves in our decision and one of the weighted rating system examples is shown below.
\begin{equation}
\textbf{Rating}(v,m,R,C) = \frac{v}{v+m} \times R + \frac{m}{v+m} \times C
\end{equation}
Where:
\\$R$ is the average rating for the item.
\\$v$ is the number of votes for the item.
\\$m$ is the minimum votes required to be listed in the popular items(defined by > percentile 80 of total votes).
\\$C$ is the average rating across the whole dataset.
THis example is used to caculate ratig scores by IMDB, which is an online database of information related to films, televison series and etc. 
Inspired by the example above, we can introduce the non-linearity in algoritms for calculate the scores of the posts to build our popularity-based recommendation system.
We wanna to construct $f(L,C,m,g)$, where $L$ is the number of likes the post received, $C$ is the number of comments the post received, 
$m$ is the minimum of likes to be listed as a popular item, $g$ is the gradient of change in number of likes in w.r.t time in recent period time.
\\The disadvantages of popularity based system is the non-personlisation.




%-----------------------------------------------------------------------------------------------------------------------------Content-Based Recommendation System
\section{Content Based Recommendation System}
Content Based Recommendation System are based on a description of the item and a profile of the user's preferences. 
These methods are best suited to situations where there is known data on an item (name, location, description, etc.), but not on the user. 
Content-based recommenders treat recommendation as a user-specific classification problem and learn a classifier for the user's likes and dislikes based on an item's features.
\\ Before we can dive into the algorithm, we must assume that there are available features that captures the content of the item.
\\ First we need to obtain the item-feature vectors, 
\begin{table}[ht]
\centering
\begin{tabular}{ |c|c|c|c|c|c|} 
 \hline
 \diagbox{Posts}{Features}&Feature1&Feature 2&Feature 3&$\cdots$&Features$j$\\
 \hline
 Post1&&&&&\\
 \hline
 Post2&&&&&\\
 \hline
 $\vdots$&&&&&\\
 \hline
 Post $i$&&&&&\\
 \hline
 \end{tabular}
 \caption{Post Feature Matrix}
 \centering
 \end{table}
The ratings given in the table measures the degree of the features in the posts, and we can assume the matrix is not sparse, which we mean the matrix is fully filled.
\\We denote that each row is the feature vector $x(i)$ for post$i$.
%
\\In addition, we need to get the profile of each individual users, which means we need to know and analyze the preference of our users, 
so we need to obtain the user parameter vector for each individual user and it reflects how the user responds to the features.
%
\\After we have post-feature matrix and user parameter vector $\theta j$ of user j, we apply similarity metrics, here we use cosine similarity to measure 
the resemblance bewteen $\theta j$ and each $x(i)$ in post-feature matrix.
\\Cosine Similarity:  As the name mentioned, It measures the cosine angle of the two vectors in the multi-dimensional space. Two things can be similar together in terms of direction rather than magnitude.
\begin{equation*}
\text{Cosine Similarity} = cos(\theta) = \frac{A \cdot B}{||A|| ||B||}
\end{equation*}
\\Our system can then recommend posts to our user$j$ based on the similarity socres.\\

The biggest problem here in our design is how can we determine the subjective features of the content, such as, genre, vibe, mood, and etc. Our current solution to this problem is including "tags" in the posts, and give limit number of choices for our users to choose from, 
and a percentage meter to indicate the degree of the features for them to set. Therefore the post-feature metrix will intensively rely on our users and it can suffer from high variance of subjectiveness.
%However, we believe this design gives our users more freedom and space to show the feelings behind the song.
\\They’re ineffective for providing recommendations for new users. When building a model you require a history of explicit / implicit user level data for the items. It’s generally important to have a large dataset of ratings available to make robust predictions without overfitting.
\\The solution to it can be solved by an UX/UI deisgn, which is inspird by Apple Music, YouTube Music and Xiaohongshu, we would pop out a page for our users to choose preference from given choices, the bubbles will have 3 sizes to indicate 'interested in', 'like' and 'very like' levels of preferences. 
\\This solves the problem with the initialisation of user parameter vector.
%
\\Content based models are most advantageous for recommending items when there is an insufficient amount of rating data available. This is because other items with similar attributes might have been rated by the user. Hence, a model should be able to leverage the ratings along with the item attributes to generate recommendations even when there isn’t a lot of data.
\\There are two main disadvantages of content based systems.
\\The recommendations provided are “obvious” based on the items / content the user has consumed. This is a disadvantage because if the user has never interacted with a particular type of item, that item will never be recommended to the user. For example, if you’ve never read mystery books, then through this approach, you will never be recommended mystery books. This is because the model is user specific and doesn’t leverage knowledge from similar users. This reduces the diversity of the recommendations, this is a negative outcome for many businesses.
\\Also people's perference will change, considering user experience, we can not ask our users to update their preference everyday or everyweek, 
and most of the time, users don't their prefernece clearly as well.

%-----------------------------------------------------------------------------------------------------------------------------Collaborative Recommendation System
\section{Collaborative Filtering Recommendation System}
Collaborative filtering is the process of predicting the interests of a user by identifying preferences and information from many users. 
This is done by filtering data for information or patterns using techniques involving collaboration among multiple agents, data sources, etc. 
The underlying intuition behind collaborative filtering is that if user A and B have similar taste in a product, then A and B are likely to have similar taste in other products as well.
\\It has a interesting property, feature learning which is that it can learn for itself what features to use.
\\We can divide collaborative filtering system into model-based approach and memory-based approach, and the memory-based approach can 
further be divided into item-based and user-based systems.

Before we dive into algorithm, we first need to construct the user-post interaction matrix \autoref{fig:UtilityM}. 
\begin{table}[ht]
\centering
\begin{tabular}{ |c|c|c|c|c|c|} 
 \hline
 \diagbox{Items}{Users}&User 1&User 2&User 3&$\cdots$&User $j$\\
 \hline
 Item1&&&&&\\
 \hline
 Item2&&&&&\\
 \hline
 Item3&&&&&\\
 \hline
 $\vdots$&&&&&\\
 \hline
 Item $i$&&&&&$y^{(i,j)} \text{ if } r(i,j) = 1$\\
 \hline
 \end{tabular}
 \caption{User-Item Interaction Matrix}
 \label{fig:UtilityM}
 \end{table}
We denote that:
\\$r(i,j) = 1$,  if user $i$ rated item $j$ ( $0$,  otherwise.)
\\$y^{(i,j)}$ \text{is the rating by user $j$ on item $i$}

The first question will be faced in this approach, that's how can we get ratings $y^{(i,j)}$, the music posts are different from the movie rating system. Considering our user experience,
we cannot ask our user to rate each post, the more sensible way is to give "Like"s. However, inspired by a Chinese video-steaming app, Bilibili, we can make some changes to the "like" system. 
Instead of "like" or "not give like", we introduce a "super like" that our user can give to a post.
\\Now we want to construct a rating function $y^{(i,j)}(L,S,T)$
\\Where 
\\$L$ is 0 if "no like is given", 1 if "liked" and 2 if "super liked", 
\\$S$ is 0 if the post has not been saved by the user and 1 if the post is saved by user
\\$T$ is how many times the user$j$ have watched post$i$, currently 
\\Formulating the equation can be another problem, like machine learning problem, we need data to fit our model or function into, which means we need to get some ratings to test or validate our rating function.
\\Hence we will randomly selects posts to ask our user to rate, 



%-----------------------------------------------------------------------------------------------------------------------------Memory-based CF
\subsection{Memory Based Approaches}
Memory based approaches are also often referred to as neighbourhood collaborative filtering. Essentially, ratings of user-item combinations are predicted on the basis of their neighbourhoods. 
This can be further split into user based collaborative filtering and item based collaborative filtering. 
User based essentially means that likeminded users are going to yield strong and similar recommendations. Item based collaborative filtering recommends items based on the similarity between items calculated using user ratings of those items.
\\The memory-based approach is so simple that It calculates the similarity matrix directly from the user-item matrix. There are two branches in memory based approaches, Item-item collaborative filtering and user-user collaborative filtering.

Pearson Correlation: The most well-known similarity metric for the linear relation is person correlation. It measures how similar two samples are based on the direction of how the value changes.
\\The method for finding the similarity between two vectors is also called \textbf{Centred Cosine Similarity}. The word "Centred" means we will normalise utility matrix first by subtracting row mean, it solves the problem when we made the assumption by assuming unrated item by user will be rated 0. 
\begin{equation*}
\text{Pearson Correlation Coefficient} = \frac{\sum(x_{i} - \bar{x})(y_{i} - \bar{y})} {\sqrt{\sum(x_{i} - \bar{x})^{2} \sum{(y_{i} - \bar{y})^{2} }}}
\end{equation*}


\subsubsection{Item-based Collaborative Filtering}
This method was first invented and used by amazon in 1998. 
Rather than matching the user to similar customers, item-to-item collaborative filtering matches each of the user’s purchased and rated items to similar items, then combines those similar items into a recommendation list. Now, let us discuss how it works.
\\ \textbf{Algorithm}:
\\Instead of applying cosine similarity, the better approah will be using pearson correlation coeffient
\\We find the group of similar items based on your similarity metric choice.
\\Select up to the top-k most similar item to recommend.


\subsubsection{User-based Collaborative Filtering}
We find the group of similar users (the group size is arbitrary) based on your similarity metric choice.
\\We average the rating of each item based on the group of similar users
\\Rank the item based on the descending average rating, and recommend the target user with the item they never interacted with before.






%-----------------------------------------------------------------------------------------------------------------------------Model-based CF
\subsection{Model Based Approaches}
Model based approaches are predictive models using machine learning. Features associated to the dataset are parameterised as inputs of the model to try to solve an optimisation related problem. Model based approaches include using things like decision trees, rule-based approaches, latent factor models etc.

\subsubsection{Optimisation Algorithm}
 
\begin{enumerate}
\item  Get the User-Item Interaction Matrix, for example, rating table.
\\ \textbf{Explicit data collection:}
\begin{itemize}
\item Asking a user to rate an item on a sliding scale.
\item Asking a user to rank a collection of items from favorite to least favorite.
\item Asking a user to create a list of items that he/she likes (see Rocchio classification or other similar techniques).
\end{itemize}

\textbf{Implicit data collection:}
\begin{itemize}
\item Analyzing the user's social network and discovering similar likes and dislikes.
\item Analyzing item/user viewing times
\end{itemize}

\begin{table}[ht]
\centering
\begin{tabular}{ |c|c|c|c|c|c|} 
 \hline
 \diagbox{Items}{Users}&User 1&User 2&User 3&$\cdots$&User $j$\\
 \hline
 Item1&&&&&\\
 \hline
 Item2&&&&&\\
 \hline
 Item3&&&&&\\
 \hline
 $\vdots$&&&&&\\
 \hline
 Item $i$&&&&&$y^{(i,j)} \text{ if } r(i,j) = 1$\\
 \hline
 \end{tabular}
 \caption{User-Item Interaction Matrix}
 \centering
 \end{table}

\item  Obtain a set of features folder, each measuring the degree of the content.
Denote that:
\\$r(i,j) = 1$,  if user $j$ rated item $i$ ( $0$,  otherwise.)
\\$y^{(i,j)}$ \text{is the rating by user $j$ on item $i$}
\\$\theta^{(i)}$ \text{is the parameter vector of user $j$}
\\$x^{(j)}$ \text{is the feature vector of item $i$}
\\$m^{(j)}$ \text{is the number of items rated by user $j$}
\\Then the predicted rate on the item $i$ by user $j$ is $(\theta^{(i)})^{T}(x^{(j)})$
\item Treat predicting the ratings of each user as a separate linear regression problem.
\item Minimise the square error term.
\end{enumerate}

Thus if we want to learn $\theta^{(i)}$ for user $j$:

\begin{equation*}
\min_{\theta^{(j)}} \frac{1}{2m^{(j)}}\sum_{i:r(i,j) = 1}\left((\theta^{(i)})^{T}x^{(j)}-y^{(i,j)}\right)^{2} + \frac{\lambda}{2m^{(j)}}\sum_{k = 1}^{n}(\theta^{(i)}_{k})^{2}
\end{equation*}
\\Where the last term is usual regularisation term to prevent the overall equation to go to infinity, to prevent overfitting.
\\ To learn $\theta^{(1)}$,$\theta^{(2)}$, \dots, $\theta^{(j)}$:
\begin{equation*}
\min_{\theta^{(1)},\theta^{(2)}, \dots, \theta^{(j)}} \frac{1}{2}\sum_{j = 1}^{n_{u}}\sum_{i:r(i,j) = 1}\left((\theta^{(i)})^{T}x^{(j)}-y^{(i,j)}\right)^{2} + \frac{\lambda}{2}\sum_{j = 1}^{n_{u}}\sum_{k = 1}^{n}(\theta^{(i)}_{k})^{2}
\end{equation*}
where $n_{u}$ is number of users, and we get rid of term $m^{(j)}$ because it is a constant which will not affect the result when we proceed the optimisation.
\begin{equation*}
\textbf{Let     } J(\theta^{(1)},\theta^{(2)}, \dots, \theta^{(j)}) = \frac{1}{2}\sum_{j = 1}^{n_{u}}\sum_{i:r(i,j) = 1}\left((\theta^{(i)})^{T}x^{(j)}-y^{(i,j)}\right)^{2} + \frac{\lambda}{2}\sum_{j = 1}^{n_{u}}\sum_{k = 1}^{n}(\theta^{(i)}_{k})^{2}
\end{equation*}
Then we apply \textbf{Gradient descent method}, 
\begin{equation*}
\\ 0 = \frac{\partial{J(\theta^{(1)},\theta^{(2)}, \dots, \theta^{(j)})}} {\partial{\theta^{(j)}}}
\end{equation*}

\textbf{Assumption:} Assume we know how much each our users love the featured items
\\Given $\theta^{(1)}$,$\theta^{(2)}$, \dots, $\theta^{(j)}$, to learn $x^{(i)}$:
\begin{equation*}
\min_{x^{(j)}} \frac{1}{2m^{(j)}}\sum_{j:r(i,j) = 1}\left((\theta^{(i)})^{T}x^{(j)}-y^{(i,j)}\right)^{2} + \frac{\lambda}{2m^{(j)}}\sum_{k = 1}^{n}(x^{(i)}_{k})^{2}
\end{equation*}
\\Where the last term is usual regularisation term to prevent the overall equation to go to infinity, to prevent overfitting.
\\Given $\theta^{(1)}$,$\theta^{(2)}$, \dots, $\theta^{(j)}$, to learn $x^{(1)}$,$x^{(2)}$,\dots,$x^{(i)}$:
\begin{equation*}
\min_{x^{(1)},x^{(2)}, \dots,x^{(j)}} \frac{1}{2}\sum_{i = 1}^{n_{m}}\sum_{i:r(i,j) = 1}\left((\theta^{(i)})^{T}x^{(j)}-y^{(i,j)}\right)^{2} + \frac{\lambda}{2}\sum_{j = 1}^{n_{m}}\sum_{k = 1}^{n}(\theta^{(i)}_{k})^{2}
\end{equation*}
The objective our Collaborative optimisation algorithm is that:
\\ If we are given $\theta^{(1)},\theta^{(2)}, \dots, \theta^{(j)}$, we are able to estimate $x^{(1)},x^{(2)}, \dots,x^{(i)}$
\\  If we are given $x^{(1)},x^{(2)}, \dots,x^{(i)}$, we are able to estimate $\theta^{(1)},\theta^{(2)}, \dots, \theta^{(j)}$
\\ So what we can do is that we can initialise $x^{(1)},x^{(2)}, \dots,x^{(j)}$, and then apply a \textbf{If loop} to repeat the steps, ideally the $x^{(i)}$ and $\theta^{(j)}$ will be improved gradually. 
\\ More wisely, we can minimise $x^{(1)},x^{(2)}, \dots,x^{(i)}$ and $\theta^{(1)},\theta^{(2)}, \dots, \theta^{(j)}$ simultaneously by combining equation[] and equation[]:

\begin{equation*}
\min_{x^{(1)},x^{(2)}, \dots,x^{(n_{m})}, \theta^{(1)},\theta^{(2)}, \dots, \theta^{(n_{u})} } 
\sum_{(i,j):r(i,j) = 1}\left((\theta^{(i)})^{T}x^{(j)}-y^{(i,j)}\right)^{2} + 
\frac{\lambda}{2}
\sum_{i=1}^{n_{m}}
\sum_{k = 1}^{n}(x^{(i)})^{2}+
\frac{\lambda}{2}
\sum_{j=1}^{n_{u}}
\sum_{k = 1}^{n}(\theta^{(j)})^{2}
\end{equation*}

\textbf{Advantages}
\\The main advantage to using collaborative filtering models is its simplicity to implement and the high level coverage they provide. It is also beneficial because it captures subtle characteristics (very true for latent factor models) and does not require understanding of the item content.
\\ \textbf{Disadvantages}
\\The main disadvantage to this model is that it’s not friendly for recommending new items, this is because there has been no user/item interaction with it. This is referred to as the cold start problem. Memory based algorithms are known to perform poorly on highly sparse datasets.
\\ \textbf{Cold start problem explain}


\subsubsection{Matrix Factorisation}
\label{MatrixFac}
Now, instead of direct computation with the user-item interaction matrix. We will decompose the user-item interaction matrix into the latent factors matrix representing the lower-dimensional space that is more useful. The idea of decomposing is we believe that the observed user-item rating matrix is constructed from the underlying user and item latent factor matrix. Suppose we can extract the best underlying latent factor matrix that minimising the loss between the reconstructed matrix and the original matrix. Then we can use the inner product of the user and item latent factor matrix for inferencing an unobserved rating.It provides a better  adjustment.
\\Matrix factorisation is a class of collaborative filtering algorithms used in recommender systems. Matrix factorisation algorithms work by decomposing the user-item interaction matrix into the product of two lower dimensionality rectangular matrices.
\\There are several kinds of matrix factorisation techniques, and each of them provides a different set of results, leading to different recommendations.
\\ \textbf{TruncatedSVD with the sklearn library}
\\TruncatedSVD is a variant of the Singular Value Decomposition that calculates only the K largest singular value (n\_components). Also, It applies the linear dimensionality reduction and works well with the sparse matrix like the user-item matrix.
\\We aim to decompose the user-item matrix into these latent factors. The value of each cell will be the estimated value that satisfies the optimization constraint (SVD assumption). An example of another matrix factorization is Non-negative matrix factorization (NMF).
\\ \textbf{Funk Matrix Factorisation}
\\It reduces the user-item interaction into the lower dimensional space latent matrix. The objective of FunkFM is to estimate the latent factor matrix and the bias termed minimising the loss between the original explicit rating and the reconstructed prediction rating.
\\ Limitation: as you can see in the rating prediction, this model only takes into account the explicit rating (a true rating that the user gives to the item), and it doesn't care about the implicit rating (the number of clicks, the time spent on the item, etc.). There is an improvement about this Limitation as well. SVD++ algorithms can be further implemented to include implicit rating into consideration.
\\\textbf{Generalized Matrix Factorization(GMF)}
 \\GMF is only part of full Neural Collaborative Filtering model.
 \\The full NCF architecture has a multi-layer perception (MLP) part. This proposed idea incorporates and activates how the model can estimate the latent factors matrix with the non-linear function. The idea is that due to the complexity of the user-item interaction matrix, only the linear product of the previous matrix factorization technique is not enough to retrieve useful information. Therefore, the idea to add the MLP part to help capture the pattern in the data is proposed.
 \begin{figure}[ht]
\centering
\includegraphics[scale = 0.5]{Figures/NCF}
\caption{Full Neural Collaborative Filtering model}
\end{figure}
 

%-----------------------------------------------------------------------------------------------------------------------------Hybrid Recommendation System
\section{Hybrid Recommendation System}
Various methods of recommendations systems have their own benefits and flaws. Often, many of these methods may seem restrictive when used in isolation, especially when multiple sources of data is available for the problem. Hybrid recommender systems are ones designed to use different available data sources to generate robust inferences.
\\Hybrid recommendation systems have two predominant designs, parallel and sequential. The parallel design provides the input to multiple recommendation systems, each of those recommendations are combined to generate one output. The sequential design provides the input parameters to a single recommendation engine, the output is passed on to the following recommender in a sequence. Refer to the figure below for a visual representation of both designs.
% \begin{figure}[ht]
% \centering
% \includegraphics[scale = 0.5]{padesign}
% \caption{Parallel design of Hybrid Recommendation System, figure here to be changed}
% \centering
% \end{figure}
% \begin{figure}[ht]
% \centering
% \includegraphics[scale = 0.5]{sedesign}
% \caption{Sequential design of Hybrid Recommendation System, figure here to be changed}
% \centering
% \end{figure}

\textbf{Advantages}
\\Hybrid systems combine different models to combat the disadvantages of one model with another. This overall reduces the weaknesses of using individual models and aids in generating more robust recommendations. This yields more robust and personalised recommendations for users.
\\\textbf{Disadvantages}
\\These types of models generally have high computational complexity and require a large database of ratings and other attributes to keep up to date. Without up to date metrics (user engagement, ratings, etc.) it makes it difficult to retrain and provide new recommendations with updated items and ratings from various users.

\section{Evaluation}
Identifying what defines a good recommendation is a problem in its self that many companies struggle with. This definition of “good” recommendations help evaluate the performance of the recommender you built. The quality of a recommendation can be assess through various tactics which measure coverage and accuracy. Accuracy is the fraction of correct recommendations out of total possible recommendations while coverage measures the fraction of objects in the search space the system is able to provide recommendations for. The method of evaluation of a recommendation is solely dependent on the dataset and approach used to generate the recommendation. Recommender systems share several conceptual similarities with the classification and regression modelling problem. In an ideal situation, you would want to see how real users react to recommendations and track metrics around the user to improve your recommendation, however, this is quite difficult to accomplish. Common statistical accuracy measures to evaluate accuracy of a recommender are RMSD, MAE, and k fold cross validation.

\subsection{K Fold Cross Validation}
This is one of the non-exhaustive validation methods, which means it does not compute all ways of splitting the original sample.

\begin{itemize}
\item Imagine you’ve built a model which will predict how well a user will rate an item based on a set of features. K fold cross validation can be used to infer the results of the model through accuracy metrics
\item Same idea as a train test split, except we create K many randomly assigned training and test sets
\item Each individual training set / fold is used to train on the recommendation system independently and then measure the accuracy of the resulting systems against the test set
\item We take the average of accuracy score to see how well the recommendation system is learning
\item This method is beneficial to prevent your model from overfitting, however it is a computationally extensive process
\end{itemize}

\subsection{Mean Absolute Error (MAE)}
Mean absolute error represents the average absolute value of each error in rating prediction
\begin{equation*}
\text{MAE} = \frac{\sum^{i=n}_{i=1}|y_{i} - x_{i}|}{n}
\end{equation*}
$y_{i}  = $ prediction
\\$x_{i}  = $ True Value
\\$n$ = total number of data points
\\Lower the MAE score the better

\subsection{Root Mean Square Deviation(RMSD)}
\begin{equation*}
\text{RMSD} = \sqrt{\frac{\sum^{i=N}_{i=1}(y_{i} - x_{i})^{2}}{N}}
\end{equation*}

\begin{itemize}
\item A similar metric to MAE but has a stronger penalty for when the prediction is very far from the true value and weaker penalty for when the prediction is closer to the true value
\item Taking the squares off the difference of true and predicted values instead of the sum of the absolute values. This ensures that the resulting value is always positive and is larger when the difference is high and smaller when the difference is low.
\item The lower the RMSD score the better
\end{itemize}


\section{Implementation}
Hybrid system:
\\Parameters: 
\\Popularity based
\\content based, Reddit's engine:  number of likes, number of comments
\\collaborative: Grouping users together
\\explicit rating: Time spent on the post
\\Detecting recent trend, user's preference change
\\ \textbf{Improvement}
\\ As we can see all the algorithm above have become an minimisation problem that we can solve by gradient descent, the typical way to solve it is to apply \textbf{Batch gradient descent}, which promises gradual approach to the global minimum . The demerit part of Batch gradient descent is that it becomes expensive when the dataset is huge, which is our current situation.
\\ \textbf{algorithm explained here}

% \begin{figure}[ht]
%      \centering
%      \hspace{8mm}
%      \begin{subfigure}[b]{0.4\textwidth}
%          \centering
%          \includegraphics[width=\textwidth]{batde}
%          \caption{Batch gradient descent}
%          \label{batde}
%      \end{subfigure}
%      \hfill
%           \begin{subfigure}[b]{0.4\textwidth}
%          \centering
%          \includegraphics[width=\textwidth]{stode}
%          \caption{Stochastic gradient descent}
%          \label{Stochastic gradient descent}
%      \end{subfigure}
%           \hspace{8mm}
%         \caption{Different Approaches, graph here to be recreated}
%         \label{Approaches}
% \end{figure}
Another approach can be {Stochastic gradient descent}, which randomly shuffle the training examples 
\\ \textbf{algorithm explained here}





